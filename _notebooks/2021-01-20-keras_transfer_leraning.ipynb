{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras transfer learning\n",
    "> Keras transfer learning\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Keras]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Transfer Learning: Grundlagen und Einsatz Gebiete\n",
    "\n",
    "- Transfer Learning ist ein Konzept aus dem Deep Learning, wo vortrainierte Modelle transferiert und in neuen Modellen zum Einsatz bringen\n",
    "- Unter Transfer-Learning versteht man das Übertragen der Ergebnisse eines fertig trainierten neuronalen Netzes auf eine neue Aufgabe\n",
    " \n",
    "Das Training eines neuen neuronalen Netzes mit einer größen Anzahl von Daten ist rechnenintersiv und zeitaufwändig. \n",
    "Wenn man ein neues neuronales Netz trainieren möchte, kann es daher sinnvoll sein, mit der Hilfe von Transfer Learning auf den bereits gelernten Features eines fertig trainierten Netzes aufzubauen. Dabei werden z.B. die fertig trainierten Layer eines CNN’s übernommen und nur der Output-Layer wird auf die Anzahl der zu erkennenden Objektklassen des neuen Netzes angepasst und nachtrainiert (Fine-Tuning).\n",
    "\n",
    "## 2. Methoden für Transfer Learning\n",
    "\n",
    "  - Merkmahle-Extrahierung\n",
    "  - Fine-Tuning\n",
    "  \n",
    "## 3. Transfer Learning mit ähnlichen Daten und kleinem Datensatz  \n",
    "Wenn die zu erkenneden Objekte änlichen Strukturen aufweisen (Hunde vs. Katze) und für die neue Aufgabe nur ein kleiner Datensazt zur Verfügung steht, kann man einfach den Output-Layer durch einen neuen ersetzen, dessen Neuronen-Anzahl mit dem Anzahl der neu zu erkennenden Klassen entspricht.  \n",
    "\n",
    "Alle andere Layern werden beibehalten und nicht weiter tranniert. Der neune Output-Layer wird mit zufällig gewählten Gewichten initialisiert un mit den neuen Datensazt traniert. Dabei durchlaufen erstmal  \n",
    "\n",
    "## 4. Transfer Learning mit unterschiedlichen Daten und kleinem Datensatz\n",
    "\n",
    "## 3. Transfer Learning mit Merkmahle Extrahierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "import random\n",
    "#from resnet import ResNet\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from pysim import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle\n",
    "from imutils import paths\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Datensatz Verzeichniss, Datensatz Verarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing 'train split'...\n",
      "[INFO] processing 'val split'...\n",
      "[INFO] processing 'test split'...\n"
     ]
    }
   ],
   "source": [
    "for split in (config.TRAIN, config.VAL, config.TEST):\n",
    "    print(\"[INFO] processing '{} split'...\".format(split))\n",
    "    imagePaths = glob.glob(os.path.sep.join([config.ORIG_INPUT_DATASET, split, '*']))\n",
    "    for imagePath in imagePaths[:96]:\n",
    "        filename =  imagePath.split(os.path.sep)[-1]\n",
    "        label = config.CLASSES[int(filename.split(\"_\")[0])]\n",
    "        #new directory path\n",
    "        newPath = os.path.sep.join([config.BASE_PATH, split, label])\n",
    "        # if directory doesn't exist than creat new\n",
    "        if not os.path.exists(newPath):\n",
    "            os.makedirs(newPath)\n",
    "        newPathFile = os.path.sep.join([newPath, filename])\n",
    "        shutil.copy2(imagePath, newPathFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Model laden  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(weights = \"imagenet\", include_top = False)\n",
    "le = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.  Markmahle extrahieren und speichern\n",
    "   - Loop over all paths \n",
    "   - Randommly shuffle paths\n",
    "   - Construct csv files were features should be written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing 'train split'...\n",
      "[INFO] processing batch 1/3\n",
      "[INFO] processing batch 2/3\n",
      "[INFO] processing batch 3/3\n",
      "[INFO] processing 'val split'...\n",
      "[INFO] processing batch 1/3\n",
      "[INFO] processing batch 2/3\n",
      "[INFO] processing batch 3/3\n",
      "[INFO] processing 'test split'...\n",
      "[INFO] processing batch 1/3\n",
      "[INFO] processing batch 2/3\n",
      "[INFO] processing batch 3/3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for split in (config.TRAIN, config.VAL, config.TEST):\n",
    "        print(\"[INFO] processing '{} split'...\".format(split))\n",
    "        p = os.path.sep.join([config.BASE_PATH, split])\n",
    "        imagePaths = list(paths.list_images(p))\n",
    "        # random shuffle the image paths and extract class labels for the file path\n",
    "        random.shuffle(imagePaths)\n",
    "        labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "        if le is  None:\n",
    "                le = LabelEncoder()\n",
    "                le.fit(labels)\n",
    "        cvsPath = os.path.sep.join([config.BASE_CSV_PATH, \"{}.csv\".format(split)]) \n",
    "        csv = open(cvsPath, \"w\")\n",
    "        for (b, i) in enumerate(range(0, len(imagePaths), config.BATCH_SIZE)):\n",
    "                    print(\"[INFO] processing batch {}/{}\".format(b + 1,\\\n",
    "                                        int(np.ceil(len(imagePaths) / float(config.BATCH_SIZE)))))\n",
    "                    batchPaths = imagePaths[i:i + config.BATCH_SIZE] \n",
    "                    batchLabels = le.fit_transform(labels[i:i + config.BATCH_SIZE])\n",
    "                    batchImages = []\n",
    "                    # loop over the images and labels in the current batch\n",
    "                    for imagePath in batchPaths:\n",
    "                    # load the input image using the Keras helper utility\n",
    "                    # while ensuring the image is resized to 224x224 pixels\n",
    "                        image = tf.keras.preprocessing.image.load_img(imagePath, target_size=(224, 224))\n",
    "                        image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "                        # preprocess the image by (1) expanding the dimensions and\n",
    "                        # (2) subtracting the mean RGB pixel intensity from the ImageNet dataset\n",
    "                        image = np.expand_dims(image, axis=0)\n",
    "                        image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "                        # add the image to the batch\n",
    "                        batchImages.append(image) \n",
    "                    # pass the images through the network and use the outputs a\n",
    "                    # our actual features, then reshape the features into a flattened volume\n",
    "                    batchImages = np.vstack(batchImages)\n",
    "                    features = model.predict(batchImages, batch_size=config.BATCH_SIZE)\n",
    "                    features = features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "\n",
    "                    # loop over the class labels and extracted features\n",
    "                    for (label, vec) in zip(batchLabels, features):\n",
    "                        # construct a row that exists of the class label and\n",
    "                        # extracted features\n",
    "                        vec = \",\".join([str(v) for v in vec])\n",
    "                        csv.write(\"{},{}\\n\".format(label, vec))\n",
    "# close the CSV file\n",
    "        csv.close()  \n",
    "# serialize the label encoder to disk\n",
    "f = open(config.LE_PATH, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close() \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. CSV-Dateien mit gespeicherten Merkmahlen laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/train.csv output/test.csv\n"
     ]
    }
   ],
   "source": [
    "# derive the paths to the training and testing CSV files\n",
    "trainingPath = os.path.sep.join([config.BASE_CSV_PATH,\"{}.csv\".format(config.TRAIN)])\n",
    "testingPath = os.path.sep.join([config.BASE_CSV_PATH, \"{}.csv\".format(config.TEST)])\n",
    "print(trainingPath, testingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_split(splitPath):\n",
    "# initialize the data and labels\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "# loop over the rows in the data split file\n",
    "    for row in open(splitPath):\n",
    "# extract the class label and features from the row\n",
    "        row = row.strip().split(\",\")\n",
    "        label = row[0]\n",
    "        features = np.array(row[1:], dtype=\"float\")\n",
    "\n",
    "# update the data and label lists\n",
    "        data.append(features)\n",
    "        labels.append(label)\n",
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "# return a tuple of the data and labels\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading data...\n"
     ]
    }
   ],
   "source": [
    "# derive the paths to the training and testing CSV files\n",
    "trainingPath = os.path.sep.join([config.BASE_CSV_PATH,\"{}.csv\".format(config.TRAIN)])\n",
    "testingPath = os.path.sep.join([config.BASE_CSV_PATH,\"{}.csv\".format(config.TEST)])\n",
    "# load the data from disk\n",
    "print(\"[INFO] loading data...\")\n",
    "(trainX, trainY) = load_data_split(trainingPath)\n",
    "(testX, testY) = load_data_split(testingPath)\n",
    "\n",
    "# load the label encoder from disk\n",
    "le = pickle.loads(open(config.LE_PATH, \"rb\").read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. Modell für classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "[INFO] evaluating...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        food       1.00      0.94      0.97        51\n",
      "    non_food       0.94      1.00      0.97        45\n",
      "\n",
      "    accuracy                           0.97        96\n",
      "   macro avg       0.97      0.97      0.97        96\n",
      "weighted avg       0.97      0.97      0.97        96\n",
      "\n",
      "[INFO] saving model...\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\",max_iter=150)\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = model.predict(testX)\n",
    "print(classification_report(testY, preds, target_names=le.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "f = open(config.MODEL_PATH, \"wb\")\n",
    "f.write(pickle.dumps(model))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenzen:\n",
    "\n",
    "> Adrian Rosebrock, OpenCV Face Recognition, PyImageSearch, https://www.pyimagesearch.com/, accessed on 3 January, 2021\n",
    "\n",
    "\n",
    "> www: https://www.pyimagesearch.com/2019/05/20/transfer-learning-with-keras-and-deep-learning/\n",
    "\n",
    "> www: https://jaai.de/transfer-learning-1739/\n",
    "\n",
    "> www: https://user.phil.hhu.de/~petersen/SoSe17_Teamprojekt/AR/neuronalenetze.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
