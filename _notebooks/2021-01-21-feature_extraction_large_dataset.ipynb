{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras transfer learning \n",
    "> Keras Tranfer Learning Feature extraction for big dataset\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Keras]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "import random\n",
    "#from resnet import ResNet\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from pysim import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle\n",
    "from imutils import paths\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Building the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in (config.TRAIN, config.VAL, config.TEST):\n",
    "    imagePaths = glob.glob(os.path.sep.join([config.ORIG_INPUT_DATASET, split, '*']))\n",
    "    for imagePath in imagePaths:\n",
    "        filename = imagePath.split(os.path.sep)[-1]\n",
    "        label = config.CLASSES[int(filename.split(\"_\")[0])]\n",
    "        newPath = os.path.sep.join([config.BASE_PATH, split, label])  \n",
    "        if not os.path.exists(newPath):\n",
    "            os.makedirs(newPath)\n",
    "        newPathFile = os.path.sep.join([newPath, filename]) \n",
    "        shutil.copy2(imagePath, newPathFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(weights = \"imagenet\", include_top = False)\n",
    "le = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Keras for deep learning feature extraction\n",
    "\n",
    "\n",
    " - Use Keras to extract features via deep learning from each image in the dataset\n",
    " - Write the class labels + extracted features to disk in CSV format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] process ... train split\n",
      "[INFO] processing batch 1/3\n",
      "[INFO] processing batch 2/3\n",
      "[INFO] processing batch 3/3\n",
      "[INFO] process ... val split\n",
      "[INFO] processing batch 1/3\n",
      "[INFO] processing batch 2/3\n",
      "[INFO] processing batch 3/3\n",
      "[INFO] process ... test split\n",
      "[INFO] processing batch 1/3\n",
      "[INFO] processing batch 2/3\n",
      "[INFO] processing batch 3/3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for split in (config.TRAIN, config.VAL, config.TEST):\n",
    "    print(\"[INFO] process ... {} split\".format(split))\n",
    "    imagePaths = glob.glob(os.path.sep.join([config.BASE_PATH, split, '*', '*']))[:94] \n",
    "    random.shuffle(imagePaths)\n",
    "    labels_ = [imagePath.split(os.path.sep)[-1] for imagePath in imagePaths]\n",
    "    labels =  [config.CLASSES[int(filename.split(\"_\")[0])] for filename in labels_]\n",
    "    if le is  None:\n",
    "                le = LabelEncoder()\n",
    "                le.fit_transform(labels)\n",
    "    cvsPath = os.path.sep.join([config.BASE_CSV_PATH, \"{}.csv\".format(split)]) \n",
    "    csv = open(cvsPath, \"w\")\n",
    "    for (b, i) in enumerate(range(0, len(imagePaths), config.BATCH_SIZE)):\n",
    "            print(\"[INFO] processing batch {}/{}\".format(b + 1,\\\n",
    "                                        int(np.ceil(len(imagePaths) / float(config.BATCH_SIZE)))))\n",
    "            batchPaths = imagePaths[i : i + config.BATCH_SIZE]\n",
    "            batchLabels = labels[i :  i + config.BATCH_SIZE]\n",
    "            batchLabels = le.transform(batchLabels)\n",
    "            batchImages = []\n",
    "            for imagePath in batchPaths:\n",
    "                    # load the input image using the Keras helper utility\n",
    "                    # while ensuring the image is resized to 224x224 pixels\n",
    "                    image = tf.keras.preprocessing.image.load_img(imagePath, target_size=(224, 224))\n",
    "                    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "                    # preprocess the image by (1) expanding the dimensions and\n",
    "                    # (2) subtracting the mean RGB pixel intensity from the ImageNet dataset\n",
    "                    image = np.expand_dims(image, axis=0)\n",
    "                    image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "                    # add the image to the batch\n",
    "                    batchImages.append(image)\n",
    "            # pass the images through the network and use the outputs a\n",
    "            # our actual features, then reshape the features into a flattened volume\n",
    "            batchImages = np.vstack(batchImages)\n",
    "            features = model.predict(batchImages, batch_size=config.BATCH_SIZE)\n",
    "            features = features.reshape((features.shape[0], 7 * 7 * 512))                         \n",
    "            # loop over the class labels and extracted features\n",
    "            for (label, vec) in zip(batchLabels, features):\n",
    "                    # construct a row that exists of the class label and\n",
    "                    # extracted features\n",
    "                    vec = \",\".join([str(v) for v in vec])\n",
    "                    csv.write(\"{},{}\\n\".format(label, vec))\n",
    "# close the CSV file\n",
    "    csv.close()  \n",
    "# serialize the label encoder to disk\n",
    "f = open(config.LE_PATH, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close() \n",
    "print(\"Done\")                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3]])\n",
    "np.array([[4,5,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Produce Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_feature_generator(inputPath, bs, numClasses, mode=\"train\"):\n",
    "    # open the input file for reading\n",
    "    f = open(inputPath, \"r\")\n",
    "    # loop indefinitely\n",
    "    while True:\n",
    "        # initialize our batch of data and labels\n",
    "        data = []\n",
    "        labels = []\n",
    "        # keep looping until we reach our batch size\n",
    "        while len(data) < bs:\n",
    "            # attempt to read the next row of the CSV file\n",
    "            row = f.readline()\n",
    "            # check to see if the row is empty, indicating we have\n",
    "            # reached the end of the file\n",
    "            if row == \"\":\n",
    "                # reset the file pointer to the beginning of the file\n",
    "                # and re-read the row\n",
    "                f.seek(0)\n",
    "                row = f.readline()\n",
    "                # if we are evaluating we should now break from our\n",
    "                # loop to ensure we don't continue to fill up the\n",
    "                # batch from samples at the beginning of the file\n",
    "                if mode == \"eval\":\n",
    "                    break\n",
    "            # extract the class label and features from the row\n",
    "            row = row.strip().split(\",\")\n",
    "            label = row[0]\n",
    "            label = to_categorical(label, num_classes=numClasses)\n",
    "            features = np.array(row[1:], dtype=\"float\")\n",
    "            # update the data and label lists\n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "        # yield the batch to the calling function\n",
    "        yield (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the label encoder from disk\n",
    "le = pickle.loads(open(config.LE_PATH, \"rb\").read())\n",
    "# derive the paths to the training, validation, and testing CSV files\n",
    "trainPath = os.path.sep.join([config.BASE_CSV_PATH,\"{}.csv\".format(config.TRAIN)])\n",
    "valPath = os.path.sep.join([config.BASE_CSV_PATH,\"{}.csv\".format(config.VAL)])\n",
    "testPath = os.path.sep.join([config.BASE_CSV_PATH,\"{}.csv\".format(config.TEST)])\n",
    "# determine the total number of images in the training and validation\n",
    "# sets\n",
    "totalTrain = sum([1 for l in open(trainPath)])\n",
    "totalVal = sum([1 for l in open(valPath)])\n",
    "# extract the testing labels from the CSV file and then determine the\n",
    "# number of testing images\n",
    "testLabels = [int(row.split(\",\")[0]) for row in open(testPath)]\n",
    "totalTest = len(testLabels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Incremental learning\n",
    "\n",
    "The Python script we’re implementing in this section will be responsible for:\n",
    "\n",
    "   - Constructing the simple feedforward NN architecture\n",
    "   - Implementing a CSV data generator used to yield batches of labels + feature vectors to the NN\n",
    "   - Training the simple NN using the data generator\n",
    "   - Evaluating the feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenzen:\n",
    "\n",
    "> Adrian Rosebrock, OpenCV Face Recognition, PyImageSearch, https://www.pyimagesearch.com/, accessed on 3 January, 2021\n",
    "\n",
    "\n",
    "> www: https://www.pyimagesearch.com/2019/05/27/keras-feature-extraction-on-large-datasets-with-deep-learning/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
