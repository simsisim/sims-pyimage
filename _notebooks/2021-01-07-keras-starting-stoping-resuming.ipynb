{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Starting, Stoping, Resuming\n",
    "> Keras Starting, Stoping, Resuming. This is the 1st step to perform when training a model. It is an exploratory approach to identify suitable learning rates. Once we have suitable learning rate we can further continue with initial learning rate finder, cycles, decay schedulers learning rates.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Keras]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Warum müssen wir das Training starten, stoppen und fortsetzen?\n",
    "\n",
    "Dies ist der 1. Schritt, der beim Training eines Modells erforderlich ist. Es ist ein exploratives Vorgehen, um geeignete Lernraten zu identifizieren. Sobald wir eine geeignete Lernrate haben, können wir weiterhin mit der Genauigkeitanpassung des Modelles anhand initial learning rate, decay and cycle schedulers fortsetzen.\n",
    "\n",
    "Es gibt eine Reihe von Gründen warum wir das Training eines Modelles starten, stoppen oder fortsetzen müssen. \n",
    "Die beiden Hauptgründe sind:\n",
    "\n",
    " -  Die Trainingssizung wird abgebrochen und das Training wird gestoppt (wegen eines Stromaussfalls, der Überschreitung einer GPU-Sitzung)\n",
    " -  Mann will direkt die Lernrate anpassen -\"on the fly\"- um die Genauigkeit des Modelles zu verbessern. Dies gescheht normalerweise durch die Verringerung der Lernate um eine Größenordnung\n",
    " \n",
    "Die Verlustfunktion eines neuronalen Netzwerkes beginnt sehr hoch, fällt aber sehr schnell ab. Die Genugkeit des Modelles ist am Anfang sehr niedrig, steigt aber sehr schenll an. Schließlich erreichen die Genauigkeit und die Verlustfunktion ein Plateau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/keras_start_resume_stop.png)\n",
    "  - Die Verlustfunktion beginnt sehr hoch, fällt dann aber schnell ab\n",
    "  - Die Genauigkeit ist anfangs sehr niedrig, steigt dann aber schnell an\n",
    "  - Schließlich erreichen Verlust und Genauigkeit ein Plateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was passiert um Epoche 30 herum?\n",
    "\n",
    "Warum sinkt der Verlust so dramatisch? Und warum steigt die Genauigkeit so gewaltig an?\n",
    "\n",
    "Der Grund für dieses Verhalten ist:\n",
    "\n",
    "   - Das Training wurde gestoppt\n",
    "   - Die Lernrate wurde um eine Größenordnung herabgesetzt (Für die Lernrate ist die Standardpraxis, sie um eine Größenordnung zu senken)\n",
    "   - Das Training wurde wieder fortgesetzt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir das Training weiter fortgeführt und die Lernrate ständing reduziert, so wird sie schließlich sehr gering sein. Je kleiner die Lernrate ist, desto geringer ist der Einfluss auf die Genauigkeit.\n",
    "\n",
    "Letztendlich gibt es zwei Probleme:\n",
    "  - Die Lernrate wird sehr klein sein, was wiederum dazu führt dass die Modell-Gewichstsaktualisierungen sehr klein werden und das Modell somit keine sinvollen Forschritte machen kann. \n",
    "  - Wir fangen an, aufgrund der kleinen Lernrate zu überanpassen. Das Modell sinkt im Bereiche mit niedrigen Verlustwerte des Verlustslandschaft an, passt sie übermässig an die Trainingsdaten an und generalisiert sich nicht auf die Validierungsdaten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Warum nicht die Lernrate-Scheduler oder Lernrate-Decay verwenden?\n",
    "\n",
    "Wann das Ziel darin besteht die Modellgenaugkeit durch das Absenken der Lernrate zu verbessern, warum dann nicht einfach die Lernrate-Scheduler oder die Lernrate-Decay zurückgreifen?  \n",
    "\n",
    "Das Problem ist dass man möglicherweise keine gute Vorstellung von der Scheduler- und Decay Parameterwerten hat:\n",
    "\n",
    "   - Die ungefähre Anzahl der Epochen, für die trainiert werden soll\n",
    "   - Was eine angemessene anfängliche Lernrate ist\n",
    "   - Welcher Lernratenbereich für CLRs verwendet werden soll, die Lernrate anzupassen und das Training an der Stelle fortzuseten an den wir aufgehört haben (Lernrate Schedueler und Decay bitten in Regel es nicht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vorteile des ctrl + c-Trainings\n",
    "\n",
    "  - Feinere Kontrolle über das Modell\n",
    "  - Bittet die Möglichkeit an das Modell bei einem bestimmten Epoch manuell zu pausieren\n",
    "  - Sobald man ein paar Experimente mit \"ctrl + c\" dürchgeführt hat, wird man eine gute Vorstellung von den geeigneten PHypaerparametern haben. Wenn das der Fall ist, kann man weiter Lernrate-Scheduler und Lernarte-Decay verwenden um die Genauigkeit des Modelles weiterhin zu erhöhen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "from resnet import ResNet\n",
    "from callbacks.epochcheckpoint import EpochCheckpoint\n",
    "from callbacks.trainingmonitor import TrainingMonitor\n",
    "import os\n",
    "import sklearn\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Argparser for model start, stop, resume\n",
    " - checkpoints paths: at each x-th epoch the model will be saved\n",
    " - if model is given than model is loaded\n",
    " - if start-epoch is given then  this epoch will be loaded for plot display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argparser for model_checkpoints, start-epoch\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-c\", \"--checkpoints\", default = \"checkpoints\", help=\"path to output checkpoint directory\")\n",
    "ap.add_argument(\"-m\", \"--model\", default = \"checkpoints/epoch_25.hdf5\", type=str, help=\"path to *specific* model checkpoint to load\")\n",
    "ap.add_argument(\"-s\", \"--start-epoch\", type=int, default=25, help=\"epoch to restart training at\")\n",
    "args = vars(ap.parse_args([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Load training tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#load training test data\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load, rescale, reshape images using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1) (10000, 32, 32, 1) (60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#fashion_mnist_dataset contains images of (28, 28), but our model was trained for images of (32,32)\n",
    "#resize all images to (32, 32)\n",
    "trainX = np.array([cv2.resize(image, (32, 32)) for image in trainX])\n",
    "testX  = np.array([cv2.resize(image,(32, 32)) for image in testX])\n",
    "#scale images between (0, 1)\n",
    "trainX = trainX.astype(\"float32\")/ 255. \n",
    "testX  = testX.astype(\"float32\")/ 255. \n",
    "#reshape data to include batch and channel dimensions --> (batch/len(dataset), size1, size2, no_channels)\n",
    "trainX = trainX.reshape(len(trainX), 32, 32, 1)\n",
    "testX  = testX.reshape(len(testX), 32, 32, 1)\n",
    "print(trainX.shape, testX.shape, trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Label Binarizer\n",
    "   - Y-data is given as numbers between 0...9 ->corresponding to 10 categories -> its shape is (no of obsevations, )\n",
    "   - Y-data is transformed into a (no of observations, 10)-matrix\n",
    "   - obs1 :(0, 0, 0, 0, 0, 1, 0, 0, 0, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binarize labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data augumentation for training and testing\n",
    "#trainAug = tf.keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model start or load\n",
    "   - if the model is loaded than we still can make changes to it and continue running it, i.e. modify the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: loading model checkpoints/epoch_25.hdf5 ...\n",
      "INFO lr = {} 0.10000000149011612\n",
      "INFO lr = {} 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "if args[\"model\"] == None:\n",
    "    optimizer = tf.keras.optimizers.SGD(lr = 0.001)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    model = ResNet.build(32, 32, 1, 10, (9, 9, 9),(64, 64, 128, 256), reg=0.0001)\n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])\n",
    "else:\n",
    "    print(\"INFO: loading model\", args[\"model\"], \"...\")\n",
    "    tf.keras.models.load_model(args[\"model\"])\n",
    "    print(\"INFO lr = {}\", format(K.get_value(model.optimizer.lr)))\n",
    "    K.set_value(model.optimizer.lr, 1e-01)\n",
    "    print(\"INFO lr = {}\", format(K.get_value(model.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Callbacks  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPath = os.path.sep.join([\"output\", \"resnet_fashion_mnist.png\"])\n",
    "jsonPath = os.path.sep.join([\"output\", \"resnet_fashion_mnist.json\"])\n",
    "# construct the set of callbacks\n",
    "callbacks = [EpochCheckpoint(args[\"checkpoints\"], every=1, startAt=args[\"start_epoch\"]), \n",
    "             TrainingMonitor(plotPath, jsonPath=jsonPath,  startAt=args[\"start_epoch\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6501 - accuracy: 0.6250checkpoints 25\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.6501 - accuracy: 0.6250 - val_loss: 0.7446 - val_accuracy: 0.2656\n",
      "Epoch 2/3\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6804 - accuracy: 0.5625checkpoints 26\n",
      "4/4 [==============================] - 3s 816ms/step - loss: 0.6804 - accuracy: 0.5625 - val_loss: 0.7338 - val_accuracy: 0.2812\n",
      "Epoch 3/3\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.4062checkpoints 27\n",
      "4/4 [==============================] - 4s 882ms/step - loss: 0.6872 - accuracy: 0.4062 - val_loss: 0.7354 - val_accuracy: 0.2344\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY = trainX[:64, :, :, :], trainY[:64]\n",
    "testX, testY   = testX[:64, :, :, :], testY[:64]\n",
    "model.fit(trainX, trainY, batch_size=8,\\\n",
    "          validation_data=(testX, testY),\\\n",
    "          steps_per_epoch=len(trainX)//16,\\\n",
    "          epochs=3, callbacks=callbacks)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "> Adrian Rosebrock, OpenCV Face Recognition, PyImageSearch, https://www.pyimagesearch.com/, accessed on 3 January, 2021\n",
    "\n",
    "\n",
    "> www: https://www.pyimagesearch.com/2019/09/23/keras-starting-stopping-and-resuming-training/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
