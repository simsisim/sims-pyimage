{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras transfer learning \n",
    "> Keras Tranfer Learning Feature extraction for big dataset\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Keras]\n",
    "- image: images/chart-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "import random\n",
    "#from resnet import ResNet\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from pysim import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle\n",
    "from imutils import paths\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesPaths = glob.glob(os.path.sep.join([config.ORIG_PATH, \"*\",\"*\"]))\n",
    "data = []\n",
    "labels = []\n",
    "random.shuffle(imagesPaths)\n",
    "for imagePath in imagesPaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (64,64))\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "data = np.array(data, dtype = \"float32\")/255.\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = tf.keras.utils.to_categorical(labels,2)\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(data, labels, test_size = 0.2, random_state = 123)\n",
    "print(trainX.shape, testX.shape, trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = tf.keras.layers.Input(shape = (64,64, 1))\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size = (7,7))(input_)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size = (5,5))(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3))(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size = (2,2))(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512)(x)\n",
    "x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Dense(2)(x)\n",
    "output = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs = [input_], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr = 0.01, decay = 1e-4/config.NUM_EPOCHS)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit(trainX, trainY, batch_size = config.BATCH_SIZE, \\\n",
    "                validation_data = (testX, testY), epochs = config.NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referenzen:\n",
    "\n",
    "> Adrian Rosebrock, OpenCV Face Recognition, PyImageSearch, https://www.pyimagesearch.com/, accessed on 3 January, 2021\n",
    "\n",
    "\n",
    "> www: https://www.pyimagesearch.com/2018/10/15/deep-learning-hydroponics-and-medical-marijuana/      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
