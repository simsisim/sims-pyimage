{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras save model using h5 format\n",
    "> Save and load model with Keras.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Keras]\n",
    "- image: images/chart-preview.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os \n",
    "import glob\n",
    "import argparse\n",
    "import random\n",
    "from resnet import ResNet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", type=str, default = \"/home/imagda/sims-data/malaria\",  help=\"path dataset of input images\")\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, default = \"/orig/\", help=\"path to trained model\")\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, default=\"plot.png\", help=\"path to output loss/accuracy plot\")\n",
    "args = vars(ap.parse_args([]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.sep.join([args[\"dataset\"], \"train\"])\n",
    "test_path  = os.path.sep.join([args[\"dataset\"], \"test\"])\n",
    "val_path   = os.path.sep.join([args[\"dataset\"], \"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22048 2756 2756\n"
     ]
    }
   ],
   "source": [
    "# data are already pre-processed and saved into coressponding folder\n",
    "tot_train_paths = glob.glob(os.path.sep.join([args[\"dataset\"], \"train\", \"*\", \"*\"]))\n",
    "tot_test_paths  = glob.glob(os.path.sep.join([args[\"dataset\"], \"test\" , \"*\", \"*\"]))\n",
    "tot_val_paths   = glob.glob(os.path.sep.join([args[\"dataset\"], \"val\"  , \"*\", \"*\"]))\n",
    "print(len(tot_train_paths), len(tot_test_paths), len(tot_val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255.)\n",
    "valAug   = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255.)\n",
    "testAug  = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 images belonging to 2 classes.\n",
      "Found 2756 images belonging to 2 classes.\n",
      "Found 2756 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(train_path, target_size = (64,64), class_mode = \"categorical\", \\\n",
    "                                        shuffle = True,color_mode = \"rgb\")\n",
    "testGen  =  testAug.flow_from_directory(test_path, target_size  = (64, 64),\\\n",
    "                                        shuffle = True, color_mode = \"rgb\", class_mode = \"categorical\")\n",
    "valGen   =   valAug.flow_from_directory(val_path, target_size = (64,64), class_mode = \"categorical\",\\\n",
    "                                       shuffle = True, color_mode = \"rgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet.build(64, 64, 3, 2, (2, 2, 3), (32, 64, 128, 256), reg=0.0005)\n",
    "optimizer = tf.keras.optimizers.SGD(lr = 0.001)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer = optimizer, loss = loss, metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainGen, steps_per_epochs = len(tot_train_path)//BATCH_SIZE,\n",
    "                    valGen, validation_steps = len(tot_train_path) //BATCH_SIZE,\n",
    "                    epochs = NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modell speichern, Vorhersage durchfÃ¼hren\n",
    "\n",
    " - model.save(\"filename\", save_format=\"h5)\n",
    "\n",
    " - model.save(\"filename.h5\")\n",
    " \n",
    "Bei Verwendung dieses Befehls wird das gesamte Modell gespeichert: Architekturen, Parameter und Gewichte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the testing generator and then use our trained model to\n",
    "# make predictions on the data\n",
    "print(\"[INFO] evaluating network...\")\n",
    "testGen.reset()\n",
    "predIdxs = model.predict(x=testGen, steps=(totalTest // BS) + 1)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testGen.classes, predIdxs,target_names=testGen.class_indices.keys()))\n",
    "\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to '{}'...\".format(args[\"model\"]))\n",
    "model.save(args[\"model\"], save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(args[\"plot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "> Adrian Rosebrock, OpenCV Face Recognition, PyImageSearch, https://www.pyimagesearch.com/, accessed on 3 January, 2021\n",
    "\n",
    "\n",
    "> www: https://www.pyimagesearch.com/2018/12/10/keras-save-and-load-your-deep-learning-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
